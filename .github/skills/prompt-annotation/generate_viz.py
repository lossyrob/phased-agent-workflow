#!/usr/bin/env python3
"""
Generate visualizations from annotated agent prompt files.

Outputs:
  - Mermaid mindmap showing annotation hierarchy
  - Markmap (markdown) interactive mindmap (collapsible nodes)
  - Mermaid flowchart skeleton from workflow steps
  - YAML structure summary with counts and classifications

Usage:
    python generate_viz.py <file.md>                    # Print all to stdout
    python generate_viz.py <file.md> --mindmap         # Print only mermaid mindmap
    python generate_viz.py <file.md> --markmap         # Print only markmap (interactive)
    python generate_viz.py <file.md> --flow            # Print only flow skeleton
    python generate_viz.py <file.md> --summary         # Print only YAML summary
    python generate_viz.py <file.md> --output <dir>    # Write files to directory

Markmap output can be viewed with:
  - VS Code extension: markmap.markmap-vscode
  - CLI: npx markmap-cli <file>.mm.md -o <file>.html
  - Web: https://markmap.js.org/repl
"""

import argparse
import re
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional


@dataclass
class AnnotationNode:
    """Represents an annotation tag with its content and children."""
    tag: str
    attributes: dict = field(default_factory=dict)
    content_snippet: str = ""
    children: list = field(default_factory=list)
    scope: Optional[str] = None
    section: str = ""  # Document section (## header) where this annotation appears
    line_number: int = 0  # Line number in source file
    
    def add_child(self, child: 'AnnotationNode'):
        self.children.append(child)


@dataclass
class ParsedAnnotations:
    """Container for all parsed annotation data."""
    root_nodes: list[AnnotationNode] = field(default_factory=list)
    workflow_steps: list[AnnotationNode] = field(default_factory=list)
    handoffs: list[AnnotationNode] = field(default_factory=list)
    guardrails: list[AnnotationNode] = field(default_factory=list)
    decision_frameworks: list[AnnotationNode] = field(default_factory=list)
    artifacts: list[AnnotationNode] = field(default_factory=list)
    quality_gates: list[AnnotationNode] = field(default_factory=list)
    agent_name: str = "Agent"
    # Maps tag type -> list of sections where it appears
    tag_sections: dict = field(default_factory=dict)
    # Maps section name -> list of (tag, node) tuples
    section_tags: dict = field(default_factory=dict)


def extract_tag_info(line: str) -> tuple[Optional[str], bool, dict]:
    """Extract tag name, closing status, and attributes from a line.
    
    Handles formats:
    - > `<tag>`
    - >- `<tag attr="value">`
    - >- - `</tag>`
    - Plain <tag> without blockquote (for chatagent blocks)
    
    Returns (tag_name, is_closing, attributes) or (None, False, {}) if no tag.
    """
    # Try blockquote format first: > `<tag>`
    match = re.search(r'`<(/?)([a-zA-Z][\w-]*)([^>]*)>`', line)
    if not match:
        # Try plain XML format: <tag> or </tag>
        match = re.search(r'<(/?)([a-zA-Z][\w-]*)([^>]*)>', line)
    
    if not match:
        return None, False, {}
    
    is_closing = match.group(1) == '/'
    tag_name = match.group(2)
    attr_string = match.group(3).strip()
    
    # Parse attributes
    attributes = {}
    for attr_match in re.finditer(r'(\w+)=["\']([^"\']*)["\']', attr_string):
        attributes[attr_match.group(1)] = attr_match.group(2)
    
    return tag_name, is_closing, attributes


def is_annotation_line(line: str) -> bool:
    """Check if line contains an XML annotation tag."""
    stripped = line.strip()
    
    # Blockquote format: > `<tag>`
    if stripped.startswith('>'):
        return bool(re.search(r'`</?[a-zA-Z][\w-]*[^>]*>`', line))
    
    # Plain XML format (for lines inside code blocks or raw): <tag>
    # Must be a standalone tag line, not prose with angle brackets
    if re.match(r'^</?[a-zA-Z][\w-]*[^>]*>\s*$', stripped):
        return True
    
    return False


def extract_content_snippet(lines: list[str], start_idx: int, max_chars: int = 50) -> str:
    """Extract a brief content snippet from lines after an opening tag."""
    snippet_parts = []
    chars_collected = 0
    
    for i in range(start_idx + 1, min(start_idx + 10, len(lines))):
        line = lines[i].strip()
        
        # Stop at closing tag or next opening tag
        if is_annotation_line(line):
            break
        
        # Skip empty lines and markdown headers for snippet
        if not line or line.startswith('#'):
            continue
        
        # Clean up the line
        clean = re.sub(r'\*\*([^*]+)\*\*', r'\1', line)  # Remove bold
        clean = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', clean)  # Remove links
        clean = clean.strip()
        
        if clean:
            snippet_parts.append(clean)
            chars_collected += len(clean)
            if chars_collected >= max_chars:
                break
    
    snippet = ' '.join(snippet_parts)[:max_chars]
    if len(snippet) == max_chars:
        snippet = snippet.rsplit(' ', 1)[0] + '...'
    return snippet


def parse_annotations(filepath: Path) -> ParsedAnnotations:
    """Parse an annotated markdown file into structured data."""
    with open(filepath, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    result = ParsedAnnotations()
    
    # Try to extract agent name from filename or content
    result.agent_name = filepath.stem.replace('.agent', '').replace('-', ' ')
    
    # Stack for building tree: list of (node, tag_name)
    node_stack: list[tuple[AnnotationNode, str]] = []
    
    # Track current document section (## headers)
    current_section = "(preamble)"
    
    for i, line in enumerate(lines):
        # Track section headers
        if line.startswith('## '):
            current_section = line[3:].strip()
            continue
        
        if not is_annotation_line(line):
            continue
        
        tag_name, is_closing, attributes = extract_tag_info(line)
        if tag_name is None:
            continue
        
        if is_closing:
            # Pop matching node from stack
            if node_stack and node_stack[-1][1] == tag_name:
                node_stack.pop()
        else:
            # Create new node with section tracking
            node = AnnotationNode(
                tag=tag_name,
                attributes=attributes,
                scope=attributes.get('scope'),
                content_snippet=extract_content_snippet(lines, i),
                section=current_section,
                line_number=i + 1  # 1-based line numbers
            )
            
            # Track tag -> sections mapping
            if tag_name not in result.tag_sections:
                result.tag_sections[tag_name] = []
            if current_section not in result.tag_sections[tag_name]:
                result.tag_sections[tag_name].append(current_section)
            
            # Track section -> tags mapping
            if current_section not in result.section_tags:
                result.section_tags[current_section] = []
            result.section_tags[current_section].append((tag_name, node))
            
            # Add to parent or root
            if node_stack:
                node_stack[-1][0].add_child(node)
            else:
                result.root_nodes.append(node)
            
            # Push onto stack
            node_stack.append((node, tag_name))
            
            # Categorize by tag type
            if tag_name == 'workflow-step':
                result.workflow_steps.append(node)
            elif tag_name == 'handoff-instruction':
                result.handoffs.append(node)
            elif tag_name == 'guardrail':
                result.guardrails.append(node)
            elif tag_name == 'decision-framework':
                result.decision_frameworks.append(node)
            elif tag_name in ('artifact-format', 'artifact'):
                result.artifacts.append(node)
            elif tag_name == 'quality-gate':
                result.quality_gates.append(node)
    
    return result


def generate_mindmap(parsed: ParsedAnnotations) -> str:
    """Generate Mermaid mindmap from parsed annotations."""
    lines = ["```mermaid", "mindmap", f"  root(({parsed.agent_name}))"]
    
    def render_node(node: AnnotationNode, depth: int):
        indent = "    " * depth
        
        # Format node label
        label = node.tag
        if node.content_snippet:
            # Truncate and escape for mermaid
            snippet = node.content_snippet[:30]
            if len(node.content_snippet) > 30:
                snippet += "..."
            snippet = snippet.replace('"', "'").replace('(', '[').replace(')', ']')
            label = f"{node.tag}: {snippet}"
        
        # Add scope indicator if present
        if node.scope:
            label = f"{label} [{node.scope}]"
        
        lines.append(f"{indent}{label}")
        
        for child in node.children:
            render_node(child, depth + 1)
    
    for node in parsed.root_nodes:
        render_node(node, 1)
    
    lines.append("```")
    return '\n'.join(lines)


def generate_markmap(parsed: ParsedAnnotations) -> str:
    """Generate Markmap (markdown) interactive mindmap from parsed annotations.
    
    Organizes by document section first, then by tag type within each section.
    This preserves document structure and makes fragmentation visible.
    
    View with:
    - VS Code extension: markmap.markmap-vscode
    - CLI: npx markmap-cli file.mm.md -o file.html
    - Web: https://markmap.js.org/repl
    """
    lines = [f"# {parsed.agent_name}"]
    
    def render_node_content(node: AnnotationNode, indent: str = ""):
        """Render a node's content and children as list items."""
        label = node.tag
        if node.content_snippet:
            snippet = node.content_snippet[:35]
            if len(node.content_snippet) > 35:
                snippet += "..."
            label = f"{label}: {snippet}"
        if node.scope:
            label = f"{label} `[{node.scope}]`"
        lines.append(f"{indent}- {label}")
        
        # Render children with deeper indent
        for child in node.children:
            render_node_content(child, indent + "  ")
    
    # Organize by document section to show structure
    for section, tags in sorted(parsed.section_tags.items()):
        # Section as level 2 header
        lines.append(f"\n## {section}")
        
        # Group tags within section
        section_tag_groups = {}
        for tag, node in tags:
            if tag not in section_tag_groups:
                section_tag_groups[tag] = []
            section_tag_groups[tag].append(node)
        
        for tag, nodes in section_tag_groups.items():
            if len(nodes) == 1:
                # Single node - render directly
                render_node_content(nodes[0])
            else:
                # Multiple nodes of same type - group under tag header
                lines.append(f"### {tag} ({len(nodes)})")
                for node in nodes:
                    render_node_content(node)
    
    return '\n'.join(lines)


def generate_markmap_by_tag(parsed: ParsedAnnotations) -> str:
    """Alternative markmap organized by tag type (shows fragmentation).
    
    Groups all same-type tags together, with section indicators showing
    where each instance comes from in the document.
    """
    lines = [f"# {parsed.agent_name} (by tag type)"]
    
    # Collect all nodes by tag type with section info
    tag_nodes = {}
    for section, tags in parsed.section_tags.items():
        for tag, node in tags:
            if tag not in tag_nodes:
                tag_nodes[tag] = []
            tag_nodes[tag].append((section, node))
    
    for tag, section_nodes in sorted(tag_nodes.items()):
        sections = set(s for s, _ in section_nodes)
        fragmented = " ⚠️" if len(sections) > 1 else ""
        lines.append(f"\n## {tag} ({len(section_nodes)}){fragmented}")
        
        # Group by section within tag
        current_section = None
        for section, node in section_nodes:
            if section != current_section:
                lines.append(f"### @{section}")
                current_section = section
            
            label = node.content_snippet[:40] if node.content_snippet else "(no content)"
            if node.scope:
                label = f"{label} `[{node.scope}]`"
            lines.append(f"- {label}")
    
    return '\n'.join(lines)


def generate_flow_skeleton(parsed: ParsedAnnotations) -> str:
    """Generate Mermaid flowchart skeleton from workflow steps and handoffs."""
    lines = ["```mermaid", "flowchart TD"]
    
    if not parsed.workflow_steps and not parsed.handoffs:
        lines.append("    start([Start]) --> no_workflow[No workflow steps found]")
        return '\n'.join(lines)
    
    # Create nodes for workflow steps
    step_ids = []
    for i, step in enumerate(parsed.workflow_steps):
        step_id = f"step{i+1}"
        step_ids.append(step_id)
        
        label = step.content_snippet[:40] if step.content_snippet else f"Step {i+1}"
        label = label.replace('"', "'").replace('[', '(').replace(']', ')')
        
        # Mark scope visually
        if step.scope == 'phase-bound':
            lines.append(f'    {step_id}["{label}"]:::phasebound')
        else:
            lines.append(f'    {step_id}["{label}"]')
    
    # Create nodes for handoffs
    handoff_ids = []
    for i, handoff in enumerate(parsed.handoffs):
        handoff_id = f"handoff{i+1}"
        handoff_ids.append(handoff_id)
        
        label = handoff.content_snippet[:40] if handoff.content_snippet else f"Handoff {i+1}"
        label = label.replace('"', "'").replace('[', '(').replace(']', ')')
        
        lines.append(f'    {handoff_id}(["{label}"]):::handoff')
    
    # Connect steps sequentially
    lines.append("")
    lines.append("    %% Sequential flow - refine with decision points")
    
    for i in range(len(step_ids) - 1):
        lines.append(f"    {step_ids[i]} --> {step_ids[i+1]}")
    
    # Connect last step to handoffs
    if step_ids and handoff_ids:
        lines.append("")
        lines.append("    %% Handoffs - add conditions as needed")
        last_step = step_ids[-1]
        for handoff_id in handoff_ids:
            lines.append(f"    {last_step} --> {handoff_id}")
    
    # Add styling
    lines.append("")
    lines.append("    %% Styling")
    lines.append("    classDef phasebound fill:#f9f,stroke:#333,stroke-width:2px")
    lines.append("    classDef handoff fill:#bbf,stroke:#333,stroke-width:2px")
    lines.append("```")
    
    return '\n'.join(lines)


def generate_summary(parsed: ParsedAnnotations) -> str:
    """Generate YAML structure summary."""
    lines = [
        f"# Structure Summary: {parsed.agent_name}",
        "",
        "counts:",
        f"  guardrails: {len(parsed.guardrails)}",
        f"  workflow_steps: {len(parsed.workflow_steps)}",
        f"  decision_frameworks: {len(parsed.decision_frameworks)}",
        f"  artifacts: {len(parsed.artifacts)}",
        f"  quality_gates: {len(parsed.quality_gates)}",
        f"  handoffs: {len(parsed.handoffs)}",
        "",
    ]
    
    # Scope breakdown
    def count_by_scope(nodes: list[AnnotationNode]) -> dict:
        counts = {'reusable': 0, 'phase-bound': 0, 'workflow': 0, 'unspecified': 0}
        for node in nodes:
            scope = node.scope if node.scope in counts else 'unspecified'
            counts[scope] += 1
        return counts
    
    all_nodes = (parsed.guardrails + parsed.workflow_steps + 
                 parsed.decision_frameworks + parsed.artifacts + 
                 parsed.quality_gates + parsed.handoffs)
    
    scope_counts = count_by_scope(all_nodes)
    lines.extend([
        "scope_breakdown:",
        f"  reusable: {scope_counts['reusable']}",
        f"  phase_bound: {scope_counts['phase-bound']}",
        f"  workflow: {scope_counts['workflow']}",
        f"  unspecified: {scope_counts['unspecified']}",
        "",
    ])
    
    # List items by category with section info
    def list_items(name: str, nodes: list[AnnotationNode]):
        if not nodes:
            return [f"{name}: []"]
        result = [f"{name}:"]
        for node in nodes:
            scope_tag = f" [{node.scope}]" if node.scope else ""
            snippet = node.content_snippet[:40] if node.content_snippet else "(no content)"
            section_tag = f" @{node.section[:25]}..." if len(node.section) > 25 else f" @{node.section}"
            result.append(f'  - "{snippet}"{scope_tag}{section_tag}')
        return result
    
    lines.extend(list_items("guardrails", parsed.guardrails))
    lines.append("")
    lines.extend(list_items("workflow_steps", parsed.workflow_steps))
    lines.append("")
    lines.extend(list_items("handoffs", parsed.handoffs))
    lines.append("")
    lines.extend(list_items("artifacts", parsed.artifacts))
    lines.append("")
    lines.extend(list_items("quality_gates", parsed.quality_gates))
    
    # Fragmentation Analysis - detect same tag types scattered across sections
    lines.extend([
        "",
        "# Fragmentation Analysis",
        "# Tags appearing in multiple sections may indicate scattered/duplicated content",
        ""
    ])
    
    fragmented_tags = {tag: sections for tag, sections in parsed.tag_sections.items() 
                       if len(sections) > 1}
    
    if fragmented_tags:
        lines.append("fragmented_tags:")
        for tag, sections in sorted(fragmented_tags.items(), 
                                     key=lambda x: len(x[1]), reverse=True):
            lines.append(f"  {tag}: # appears in {len(sections)} sections")
            for section in sections:
                # Count how many of this tag in this section
                count = sum(1 for t, _ in parsed.section_tags.get(section, []) if t == tag)
                lines.append(f"    - \"{section}\" ({count}x)")
    else:
        lines.append("fragmented_tags: none  # All tag types are consolidated")
    
    # Section overview - what's in each section
    lines.extend([
        "",
        "# Section Overview",
        "sections:"
    ])
    
    for section, tags in sorted(parsed.section_tags.items()):
        tag_counts = {}
        for tag, _ in tags:
            tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        lines.append(f'  "{section}":')
        for tag, count in sorted(tag_counts.items()):
            lines.append(f"    {tag}: {count}")
    
    # Gap detection
    lines.extend([
        "",
        "# Gap Detection",
        "potential_gaps:"
    ])
    
    if not parsed.guardrails:
        lines.append("  - WARNING: No guardrails found")
    if not parsed.workflow_steps:
        lines.append("  - WARNING: No workflow steps found")
    if not parsed.handoffs:
        lines.append("  - WARNING: No handoff instructions found")
    if not parsed.quality_gates:
        lines.append("  - NOTE: No quality gates found (may be intentional)")
    if scope_counts['unspecified'] > scope_counts['reusable'] + scope_counts['phase-bound']:
        lines.append("  - NOTE: Most annotations lack scope classification")
    
    # Fragmentation warnings
    for tag, sections in fragmented_tags.items():
        if tag in ('guardrail', 'workflow-step', 'decision-framework'):
            lines.append(f"  - NOTE: <{tag}> spread across {len(sections)} sections - consider consolidation")
    
    if len(lines) == lines.index("potential_gaps:") + 1:
        lines.append("  - None detected")
    
    return '\n'.join(lines)


def main():
    parser = argparse.ArgumentParser(
        description='Generate visualizations from annotated agent prompts.',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument('file', type=Path, help='Path to annotated markdown file')
    parser.add_argument('--mindmap', action='store_true', help='Output only mermaid mindmap')
    parser.add_argument('--markmap', action='store_true', help='Output only markmap (interactive)')
    parser.add_argument('--flow', action='store_true', help='Output only flow skeleton')
    parser.add_argument('--summary', action='store_true', help='Output only YAML summary')
    parser.add_argument('--output', '-o', type=Path, help='Directory to write output files')
    
    args = parser.parse_args()
    
    if not args.file.exists():
        print(f"Error: File not found: {args.file}", file=sys.stderr)
        sys.exit(1)
    
    # Parse the file
    parsed = parse_annotations(args.file)
    
    # Generate outputs
    mindmap = generate_mindmap(parsed)
    markmap = generate_markmap(parsed)
    markmap_by_tag = generate_markmap_by_tag(parsed)
    flow = generate_flow_skeleton(parsed)
    summary = generate_summary(parsed)
    
    # Determine what to output
    show_all = not (args.mindmap or args.markmap or args.flow or args.summary)
    
    if args.output:
        # Write to files
        args.output.mkdir(parents=True, exist_ok=True)
        base_name = args.file.stem.replace('.agent', '')
        
        mindmap_path = args.output / f"{base_name}-mindmap.mmd"
        markmap_path = args.output / f"{base_name}-by-section.mm.md"
        markmap_tag_path = args.output / f"{base_name}-by-tag.mm.md"
        flow_path = args.output / f"{base_name}-flow.mmd"
        summary_path = args.output / f"{base_name}-summary.yaml"
        
        with open(mindmap_path, 'w') as f:
            f.write(mindmap)
        with open(markmap_path, 'w') as f:
            f.write(markmap)
        with open(markmap_tag_path, 'w') as f:
            f.write(markmap_by_tag)
        with open(flow_path, 'w') as f:
            f.write(flow)
        with open(summary_path, 'w') as f:
            f.write(summary)
        
        print(f"Generated:")
        print(f"  {mindmap_path}")
        print(f"  {markmap_path} (by section - shows document structure)")
        print(f"  {markmap_tag_path} (by tag - shows fragmentation with ⚠️)")
        print(f"  {flow_path}")
        print(f"  {summary_path}")
    else:
        # Print to stdout
        outputs = []
        
        if show_all or args.mindmap:
            outputs.append(("MINDMAP (Mermaid)", mindmap))
        if show_all or args.markmap:
            outputs.append(("MINDMAP (Markmap - Interactive)", markmap))
        if show_all or args.flow:
            outputs.append(("FLOW SKELETON", flow))
        if show_all or args.summary:
            outputs.append(("STRUCTURE SUMMARY", summary))
        
        for i, (title, content) in enumerate(outputs):
            if i > 0:
                print("\n" + "="*60 + "\n")
            if len(outputs) > 1:
                print(f"### {title} ###\n")
            print(content)


if __name__ == '__main__':
    main()
